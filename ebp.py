# -*- coding: utf-8 -*-
"""EBP.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1ddAJHqGcNZl6kvujx2_-s_9O8vDjWL6L

EMPLOYEE BURNOUT PREDICTION

IMPORTING NECESSARY LIBRARIES
"""

import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.model_selection import train_test_split
from sklearn.preprocessing import MinMaxScaler
from sklearn.linear_model import LinearRegression
from sklearn.metrics import mean_squared_error, mean_absolute_error, r2_score
import pickle
from google.colab import files
uploaded = files.upload()

"""LOADING DATASET"""

data=pd.read_excel(r"employee_burnout_analysis-AI.xlsx")

"""DATA OVERVIEW"""

data.head()

data.tail()

data.describe()

data.columns.tolist()

data.nunique()

data.info()

data.isnull().sum()

data.isnull().sum().values.sum()

"""EXPLORATORY DATA ANALYSIS"""

data.corr(numeric_only=True)['Burn Rate'][:-1]

sns.pairplot(data)
plt.show()

data=data.dropna()

data.shape

data.dtypes

data_obj = data.select_dtypes(object)
print({c: data_obj[c].unique()[:10] for c in data_obj.columns})

print(data.columns)

data=data.drop('Employee ID',axis=1)

"""CORRELATION OF DATE OF JOINING WITH TARGET VARIABLE"""

print(f"Min data {data['Date of Joining'].min()}")
print(f"Max data {data['Date of Joining'].max()}")
data.month=data.copy()

data.month['Date of Joining']=data.month['Date of Joining'].astype("datetime64[ns]")
data.month['Date of Joining'].groupby(data.month['Date of Joining'].dt.month).count().plot(kind="bar",xlabel="Month",ylabel="Hired Employees")

data_2008=pd.to_datetime(["2008-01-01"]*len(data))
data["Days"]=data['Date of Joining'].astype("datetime64[ns]").sub(data_2008).dt.days
data.Days

numeric_data=data.select_dtypes(include=['number'])
correlation=numeric_data.corr()['Burn Rate']
print(correlation)

data.corr(numeric_only=True)['Burn Rate'][:-1]

"""We observed that there is no strong correlation between Date of Joining and Burn Rate.So, we are dropping the column Date of Joining"""

data=data.drop(['Date of Joining','Days'],axis=1)

data.head()

"""Now analysing the categorical variables"""

cat_columns=data.select_dtypes(object).columns
fig,ax=plt.subplots(nrows=1,ncols=len(cat_columns),sharey=True,figsize=(10,5))
for i,c in enumerate(cat_columns):
    sns.countplot(x=c,data=data,ax=ax[i])
plt.show()

"""The number of observations of each category on each variable is equally distributed, except to the Company_Type where the number of service jobs its almost twice that of product ones."""

for c in data.select_dtypes(object).columns:
    sns.pairplot(data, hue=c)

plt.show()

"""One-Hot Encoding for categorical features"""

if all(col in data.columns for col in ['Company Type','WFH Setup Available','Gender']):
  data=pd.get_dummies(data,columns=['Company Type','WFH Setup Available','Gender'],drop_first=True)
  data.head()
  encoded_columns=data.columns
else:
  print("Error: One or more of the specified columns are not present in the DataFrame.")
  encoded_columns=None
  print(data.columns)

# Calculating the IQR only for numerical columns
numerical_columns = data.select_dtypes(include=[np.number]).columns

Q1 = data[numerical_columns].quantile(0.25)
Q3 = data[numerical_columns].quantile(0.75)
IQR = Q3 - Q1

# Filtering out the outliers for numerical columns
data = data[~((data[numerical_columns] < (Q1 - 1.5 * IQR)) | (data[numerical_columns] > (Q3 + 1.5 * IQR))).any(axis=1)]

print(data.shape)

data.corr(numeric_only=True)['Burn Rate'][:-1]

data=data.drop('Company Type_Service', axis=1)
data=data.drop('WFH Setup Available_Yes', axis=1)
data=data.drop('Gender_Male', axis=1)

# @title Preprocessing

#split df into X and Y
Y=data['Burn Rate']
X=data.drop('Burn Rate',axis=1)

#Train-test split
X_train, X_test, Y_train, Y_test = train_test_split(X, Y, train_size=0.7, shuffle=True, random_state=1)

# scale X
scaler= MinMaxScaler()
scaler.fit(X_train)
X_train=pd.DataFrame(scaler.transform(X_train),index=X_train.index,columns=X_train.columns)
X_test=pd.DataFrame(scaler.transform(X_test),index=X_test.index,columns=X_test.columns)

import os
import pickle

scaler_filename='../models/scaler.pkl'

os.makedirs(os.path.dirname(scaler_filename), exist_ok=True)
with open(scaler_filename, 'wb') as file:
    pickle.dump(scaler, file)

X_train

Y_train

import os
import pickle

#saving the processed data
path='../data/processed/'

#create the directory if it doesn't exist
os.makedirs(path, exist_ok=True)

X_train.to_csv(path+'X_train_processed.csv', index=False)
Y_train.to_csv(path+'Y_train_processed.csv', index=False)

"""MODEL BUILDING"""

# @title Linear Regression

#from sklearn.linear_model import LinearRegression

#create an instance of the LinearRegression class
linear_regression_model = LinearRegression()

#Train the data
linear_regression_model.fit(X_train,Y_train)

#Linear Regressing Model Performance Metrics

print("Linear Regression Model Performance Metrics:\n")
#make predictions on the test set
Y_pred=linear_regression_model.predict(X_test)

#calculate mean squared error
mse=mean_squared_error(Y_test,Y_pred)
print("Mean Squared Error:",mse)

#calculate root mean squared error
rmse=mean_squared_error(Y_test,Y_pred,squared=False)
print("Root Mean Squared Error:",rmse)

#calculate mean absolute error
mae=mean_absolute_error(Y_test,Y_pred)
print("Mean Absolute Error:",mae)

#calculate R-squared score
r2=r2_score(Y_test,Y_pred)
print("R-Squared score:",r2)

"""Based in the evaluation metrics, the Linear Regression model appears to be the best model for predicting burnout analysis.

It has the lowest mean squared error, root mean squared error and mean absolute error, indicating better accuracy and precision in its predictions. Additionally, it has the highest R-squared score, indicating a good fit to the data and explaining a higher proportion of the variance in the target variable.

So we are choosing this model for deployment.
"""

data

new_data = {
    'Designation': [0.5751],
    'Resource Allocation': [0.6247],
    'Mental Fatigue Score': [0.7813]
}
new_inp = pd.DataFrame(new_data)
new_predict = linear_regression_model.predict(new_inp)
print("Prediction of burnout of an employee is:", new_predict)
